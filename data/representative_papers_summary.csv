TITLE,AUTHOR,YEAR,JOURNAL,ABSTRACT,DOI,Topic
New paradigms for exploiting parallel experiments in Bayesian optimization,NA,2023,Computers & Chemical Engineering,"Bayesian optimization (BO) is one of the most effective methods for closed-loop experimental design and black-box optimization. However, a key limitation of BO is that it is an inherently sequential algorithm (one experiment is proposed per round) and thus cannot directly exploit high-throughput (parallel) experiments. Diverse modifications to the BO framework have been proposed in the literature to enable exploitation of parallel experiments but such approaches are limited in the degree of parallelization that they can achieve and can lead to redundant experiments (thus wasting resources and potentially compromising performance). In this work, we present new parallel BO paradigms that exploit the structure of the system to partition the design space. Specifically, we propose an approach that partitions the design space by following the level sets of the performance function and an approach that exploits the partially separable structure of the performance function found. We conduct extensive numerical experiments using a reactor case study to benchmark the effectiveness of these approaches against a variety of state-of-the-art parallel algorithms reported in the literature. Our computational results show that our approaches significantly reduce the required search time and increase the probability of finding a global (rather than local) solution.",https://doi.org/10.1016/j.compchemeng.2022.108110,Bayesian & Optimization Approaches
HEX: Human-in-the-loop explainability via deep reinforcement learning,NA,2024,Decision Support Systems,"The use of machine learning (ML) models in decision-making contexts, particularly those used in high-stakes decision-making, are fraught with issue and peril since a person – not a machine – must ultimately be held accountable for the consequences of decisions made using such systems. Machine learning explainability (MLX) promises to provide decision-makers with prediction-specific rationale, assuring them that the model-elicited predictions are made for the right reasons and are thus reliable. Few works explicitly consider this key human-in-the-loop (HITL) component, however. In this work we propose HEX, a human-in-the-loop deep reinforcement learning approach to MLX. HEX incorporates 0-distrust projection to synthesize decider-specific explainers that produce explanations strictly in terms of a decider’s preferred explanatory features using any classification model. Our formulation explicitly considers the decision boundary of the ML model in question using a proposed explanatory point mode of explanation, thus ensuring explanations are specific to the ML model in question. We empirically evaluate HEX against other competing methods, finding that HEX is competitive with the state-of-the-art and outperforms other methods in human-in-the-loop scenarios. We conduct a randomized, controlled laboratory experiment utilizing actual explanations elicited from both HEX and competing methods. We causally establish that our method increases decider’s trust and tendency to rely on trusted features.",https://doi.org/10.1016/j.dss.2024.114304,Policy & Expert-Guided Decision Models
Human-algorithm collaborative Bayesian optimization for engineering systems,NA,2024,Computers & Chemical Engineering,"Bayesian optimization has proven effective for optimizing expensive-to-evaluate functions in Chemical Engineering. However, valuable physical insights from domain experts are often overlooked. This article introduces a collaborative Bayesian optimization approach that re-integrates human input into the data-driven decision-making process. By combining high-throughput Bayesian optimization with discrete decision theory, experts can influence the selection of experiments via a discrete choice. We propose a multi-objective approach togenerate a set of high-utility and distinct solutions, from which the expert selects the desired solution for evaluation at each iteration. Our methodology maintains the advantages of Bayesian optimization while incorporating expert knowledge and improving accountability. The approach is demonstrated across various case studies, including bioprocess optimization and reactor geometry design, demonstrating that even with an uninformed practitioner, the algorithm recovers the regret of standard Bayesian optimization. By including continuous expert opinion, the proposed method enables faster convergence and improved accountability for Bayesian optimization in engineering systems.",https://doi.org/10.1016/j.compchemeng.2024.108810,Policy & Expert-Guided Decision Models
Optimization of multi-echelon spare parts inventory systems using multi-agent deep reinforcement learning,NA,2024,Applied Mathematical Modelling,"Multi-echelon inventory systems are commonly used in practice to satisfy widely distributed random demands of spare parts in an efficient and cost-effective manner. Optimization of a multi-echelon inventory system is a decision-making problem under uncertainties. Classic inventory policies (e.g. (s, S) and (R, Q)) that do not consider the inventory positions of other warehouses become suboptimal due to interrelationships among different warehouses caused by transshipment. The Markov decision process (MDP) is an effective tool for inventory optimization, which does not require a predetermined parameterized policy structure. Unfortunately, both the state and action spaces of MDP suffer from the curse of dimensionality when the number of warehouses increases. This paper optimizes the inventory of a large-scale multi-echelon inventory system using a new multi-agent deep reinforcement learning (MADRL) algorithm named EM-VDTD3 that is developed by introducing value decomposition and experience buffer modification into the twin delayed deep deterministic policy gradient (TD3) algorithm. Each agent in EM-VDTD3 manages a subsystem in the multi-echelon inventory system. Because different agents share the same network parameters, networks are customized to process subsystems with different parameters. Domain knowledge of inventory control is embedded in the learning process of EM-VDTD3 by adding expert experiences to the experience buffer. An efficient approximate method is developed to identify a teacher policy that generates expert experiences. Numerical studies about a spare part inventory system in the wind energy industry show that the proposed EM-VDTD3 outperforms benchmark methods.",https://doi.org/10.1016/j.apm.2023.10.039,Policy & Expert-Guided Decision Models
